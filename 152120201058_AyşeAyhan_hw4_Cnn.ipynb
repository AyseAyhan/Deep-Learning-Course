{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#ASIL\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Swish(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x * torch.sigmoid(x)\n",
        "\n",
        "#CNN MODEL\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "        self.conv4 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)\n",
        "        self.conv5 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv6 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "        self.conv7 = nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1)\n",
        "        self.conv8 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv9 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
        "        self.swish = Swish()\n",
        "        self.avg_pool = nn.AvgPool2d(4)\n",
        "        self.fc1 = nn.Linear(1024, 1024)\n",
        "        self.fc2 = nn.Linear(1024, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        c1 = self.swish(self.conv1(x))\n",
        "        c2 = self.swish(self.conv2(c1))\n",
        "        c3 = self.swish(self.conv3(c2))\n",
        "        out1 = c1 + c3\n",
        "\n",
        "        c4 = self.swish(self.conv4(out1))\n",
        "        c5 = self.swish(self.conv5(c4))\n",
        "        c6 = self.swish(self.conv6(c5))\n",
        "        out2 = c4 + c6\n",
        "\n",
        "        c7 = self.swish(self.conv7(out2))\n",
        "        c8 = self.swish(self.conv8(c7))\n",
        "        c9 = self.swish(self.conv9(c8))\n",
        "        out3 = c7 + c9\n",
        "\n",
        "        out4 = self.avg_pool(out3)\n",
        "        out5 = out4.view(out4.size(0), -1)\n",
        "        out6 = self.fc1(out5)\n",
        "        out7 = self.fc2(out6)\n",
        "\n",
        "        return out7\n",
        "\n",
        "\n",
        "# Load the dataset\n",
        "transform = transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])\n",
        "train_set = datasets.ImageFolder(root='/content/drive/MyDrive/CaltechTinySplit/train', transform=transform)\n",
        "test_set = datasets.ImageFolder(root='/content/drive/MyDrive/CaltechTinySplit/test', transform=transform)\n",
        "val_set = datasets.ImageFolder(root='/content/drive/MyDrive/CaltechTinySplit/val', transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_set, batch_size=16, shuffle=False)\n",
        "val_loader = DataLoader(val_set, batch_size=16, shuffle=False)\n",
        "\n",
        "# Initialize the model, optimizer, and loss function\n",
        "model = CNN(num_classes=9)\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(60):\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# Save the model\n",
        "torch.save(model.state_dict(), 'model.pth')\n",
        "\n",
        "# Load and evaluate the model\n",
        "model.load_state_dict(torch.load('model.pth'))\n",
        "model.eval()\n",
        "\n",
        "# Evaluate the model using the test dataset\n",
        "correct = 0\n",
        "total = 0\n",
        "all_labels = []\n",
        "all_predicted = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        all_labels.extend(labels.numpy())\n",
        "        all_predicted.extend(predicted.numpy())\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Accuracy: {accuracy:.2f}%')\n",
        "\n",
        "# Calculate confusion matrix and F-score\n",
        "conf_matrix = confusion_matrix(all_labels, all_predicted)\n",
        "f_score = f1_score(all_labels, all_predicted, average='macro')\n",
        "\n",
        "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
        "print(f'F-score: {f_score:.4f}')"
      ],
      "metadata": {
        "id": "mbkHJAoQJ0Zt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Her epoch için loss fonksiyonu, accuracy ve f-score görüntülemek için\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms, datasets\n",
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "import numpy as np\n",
        "\n",
        "class Swish(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x * torch.sigmoid(x)\n",
        "\n",
        "# CNN\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "        self.conv4 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)\n",
        "        self.conv5 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv6 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "        self.conv7 = nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1)\n",
        "        self.conv8 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv9 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
        "        self.swish = Swish()\n",
        "        self.avg_pool = nn.AvgPool2d(4)\n",
        "        self.fc1 = nn.Linear(1024, 1024)\n",
        "        self.fc2 = nn.Linear(1024, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        c1 = self.swish(self.conv1(x))\n",
        "        c2 = self.swish(self.conv2(c1))\n",
        "        c3 = self.swish(self.conv3(c2))\n",
        "        out1 = c1 + c3\n",
        "\n",
        "        c4 = self.swish(self.conv4(out1))\n",
        "        c5 = self.swish(self.conv5(c4))\n",
        "        c6 = self.swish(self.conv6(c5))\n",
        "        out2 = c4 + c6\n",
        "\n",
        "        c7 = self.swish(self.conv7(out2))\n",
        "        c8 = self.swish(self.conv8(c7))\n",
        "        c9 = self.swish(self.conv9(c8))\n",
        "        out3 = c7 + c9\n",
        "\n",
        "        out4 = self.avg_pool(out3)\n",
        "        out5 = out4.view(out4.size(0), -1)\n",
        "        out6 = self.fc1(out5)\n",
        "        out7 = self.fc2(out6)\n",
        "\n",
        "        return out7\n",
        "\n",
        "# Load the dataset\n",
        "transform = transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])\n",
        "train_set = datasets.ImageFolder(root='/content/drive/MyDrive/CaltechTinySplit/train', transform=transform)\n",
        "test_set = datasets.ImageFolder(root='/content/drive/MyDrive/CaltechTinySplit/test', transform=transform)\n",
        "val_set = datasets.ImageFolder(root='/content/drive/MyDrive/CaltechTinySplit/val', transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_set, batch_size=16, shuffle=False)\n",
        "val_loader = DataLoader(val_set, batch_size=16, shuffle=False)\n",
        "\n",
        "# Initialize the model, optimizer, and loss function\n",
        "model = CNN(num_classes=9)\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(60):\n",
        "    total_loss = 0  # to keep track of the total loss for each epoch\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_labels = []\n",
        "    all_predicted = []\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Calculate training accuracy and store predictions for later use\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        all_labels.extend(labels.numpy())\n",
        "        all_predicted.extend(predicted.numpy())\n",
        "\n",
        "        # Accumulate the total loss for the epoch\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # Calculate average loss for the epoch\n",
        "    average_loss = total_loss / len(train_loader)\n",
        "\n",
        "    # Calculate accuracy for the epoch\n",
        "    accuracy = 100 * correct / total\n",
        "\n",
        "    # Calculate F-score for the epoch\n",
        "    f_score = f1_score(all_labels, all_predicted, average='macro')\n",
        "\n",
        "    # Print metrics for the epoch\n",
        "    print(f'Epoch [{epoch + 1}/60], Loss: {average_loss:.4f}, Accuracy: {accuracy:.2f}%, F-score: {f_score:.4f}')\n",
        "\n",
        "# Save the model\n",
        "torch.save(model.state_dict(), 'model.pth')\n",
        "\n",
        "# Load and evaluate the model\n",
        "model.load_state_dict(torch.load('model.pth'))\n",
        "model.eval()\n",
        "\n",
        "# Evaluate the model using the test dataset\n",
        "correct = 0\n",
        "total = 0\n",
        "all_labels = []\n",
        "all_predicted = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        all_labels.extend(labels.numpy())\n",
        "        all_predicted.extend(predicted.numpy())\n",
        "\n",
        "# Calculate accuracy, confusion matrix, and F-score for the test dataset\n",
        "accuracy = 100 * correct / total\n",
        "conf_matrix = confusion_matrix(all_labels, all_predicted)\n",
        "f_score = f1_score(all_labels, all_predicted, average='macro')\n",
        "\n",
        "print(f'Test Accuracy: {accuracy:.2f}%')\n",
        "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
        "print(f'F-score: {f_score:.4f}')\n"
      ],
      "metadata": {
        "id": "bwFjjvRfJ1mf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}